- include_vars: monitoring-vars.yml
  tags: always

- include_vars: secrets-wwp.yml
  tags: always

- name: "Pull traefik image into {{ monitoring_traefik_base_image_mirrored_to }}"
  delegate_to: localhost
  tags: monitoring.prometheus
  openshift_imagestream:
    metadata:
      name: traefik
      namespace: "{{ openshift_namespace }}"
    from: "{{ monitoring_traefik_base_image_mirrored_from }}"
    tag: latest

- name: Prometheus service
  tags: monitoring.prometheus
  openshift:
    state: latest
    apiVersion: v1
    kind: Service
    metadata:
      name: prometheus
      namespace: "{{ openshift_namespace }}"
      labels:
        app: prometheus
    spec:
      ports:
        - name: traefik
          port: 9999
      selector:
        app: prometheus

- name: Prometheus route (https://prometheus-wwp.epfl.ch/)
  tags: monitoring.prometheus
  openshift:
    state: latest
    apiVersion: route.openshift.io/v1
    kind: Route
    metadata:
      name: prometheus
      namespace: "{{ openshift_namespace }}"
    spec:
      host: prometheus-wwp.epfl.ch
      port:
        targetPort: traefik
      tls:
        termination: edge
      to:
        kind: Service
        name: prometheus

- name: Prometheus StatefulSet
  tags: monitoring.prometheus
  vars:
    # https://docs.openshift.com/container-platform/3.11/dev_guide/managing_images.html#image-stream-kubernetes-resources
    _openshift_image_triggers: >-
      {{ [dict(from=
                     dict(kind="ImageStreamTag",
                          name=monitoring_prober_image_name + ":latest",
                          namespace="wwp"),
                   fieldPath='spec.template.spec.containers[?(@.name=="prober")].image'
                  )] }}
  openshift:
    state: latest
    apiVersion: apps/v1
    kind: StatefulSet
    metadata:
      name: prometheus
      namespace: "{{ openshift_namespace }}"
      annotations:
        # Note: *do not* snap definition of _openshift_image_triggers (above)
        # into place (or if you do, reformat it first). Use git blame to
        # figure out why.
        image.openshift.io/triggers: >-
          {{ _openshift_image_triggers | to_json }}

    spec:
      serviceName: prometheus  # Refs the service above, so that the pods get
                               # a predictable KubeDNS name
      selector:
        matchLabels:
          app: prometheus
      template:
        metadata:
          labels:
            app: prometheus
        spec:
          terminationGracePeriodSeconds: 10
          containers:
            - name: prometheus
              image: quay.io/prometheus/prometheus
              volumeMounts:
                - name: storage
                  mountPath: /prometheus
                - name: dynamic-config
                  mountPath: /prometheus-config/dynamic
                - name: static-config
                  mountPath: /prometheus-config/static
              command:
                - /bin/prometheus
                - --config.file=/prometheus-config/static/prometheus.yml
                - --storage.tsdb.path=/prometheus
                - --query.lookback-delta=15m     # Menu values change slowly
                - --web.console.libraries=/usr/share/prometheus/console_libraries
                - --web.console.templates=/usr/share/prometheus/consoles/prometheus
            - name: traefik
              image: "{{ monitoring_traefik_base_image_mirrored_to }}"
              ports:
              - containerPort: 9999
                name: traefik
              volumeMounts:
                - name: traefik-config-static
                  mountPath: /etc/traefik
                - name: traefik-config-dynamic
                  mountPath: /etc/traefik/dynamic
            - name: configurator
              image: quay.io/ansible/python-base
              volumeMounts:
                - name: dynamic-config
                  mountPath: /prometheus-config/dynamic
                - name: static-config
                  mountPath: /prometheus-config/static
              command:
                    - /usr/bin/env
                    - python3
                    - /prometheus-config/static/prometheus-menu-service-discovery.py
            - name: prober
              # image for this one is obtained by trigger (see
              # above) from the ImageStreamTag
              # This container is otherwise stateless
          volumes:
            - name: storage
              emptyDir: {}  # TODO We probably want some persistence here
            - name: dynamic-config
              emptyDir: {}
            - name: static-config
              configMap:
                name: prometheus
            - name: traefik-config-static
              configMap:
                name: traefik
            - name: traefik-config-dynamic
              configMap:
                name: traefikdyna

- name: Prometheus ConfigMap (configuration and sync scripts)
  openshift:
    state: latest
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: prometheus
      namespace: "{{ openshift_namespace }}"
    data:
      prometheus.yml: >
        {{ lookup("template", "prometheus-config.yml") }}
      prometheus-menu-service-discovery.py: >
        {{ lookup("template", "prometheus-menu-service-discovery.py") }}

- name: Traefik ConfigMap Static (configuration and sync scripts)
  openshift:
    state: latest
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: traefik
      namespace: "{{ openshift_namespace }}"
    data:
      traefik.yml: >
        {{ lookup("template", "traefik-config-static.yml") }}

- name: Traefik ConfigMap Dynamic (configuration and sync scripts)
  openshift:
    state: latest
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: traefikdyna
      namespace: "{{ openshift_namespace }}"
    data:
      basic-auth.yml: >
        {{ lookup("template", "traefik-config-dynamic.yml") }}

- name: "ImageStream/monitoring-wpprobe and BuildConfig/monitoring-wpprobe"
  openshift_imagestream:
    name: "{{ monitoring_prober_image_name }}"
    namespace: "{{ openshift_namespace }}"
    git:
      repository: https://github.com/epfl-si/wp-ops
      path: docker/monitoring-wpprobe
    metadata:
      labels:
        app: prometheus
        rebuild: changeMe
  register: _openshift_imagestream_monitoring_wpprobe

- name: "Rebuild {{ monitoring_prober_image_name }} now"
  when: _openshift_imagestream_monitoring_wpprobe is changed
  shell: "oc -n {{ openshift_namespace }} start-build --wait {{ monitoring_prober_image_name }}"
  delegate_to: localhost

- name: "ImageStream/monitoring-disk-usage-report, BuildConfig/monitoring-disk-usage-report and Secret/monitoring-disk-usage-report-webhook"
  openshift_imagestream:
    name: "{{ monitoring_disk_usage_report_image_name }}"
    namespace: "{{ openshift_namespace }}"
    git:
      repository: https://github.com/epfl-si/wp-ops
      path: docker/disk-usage-statistics
      webhook_secret: "{{ monitoring_disk_usage_report_webhook_secret }}"
    metadata:
      labels:
        app: prometheus
  register: _openshift_imagestream_disk_usage_report

- name: "Rebuild {{ monitoring_disk_usage_report_image_name }} now"
  when: _openshift_imagestream_disk_usage_report is changed
  shell: "oc -n {{ openshift_namespace }} start-build --wait {{ monitoring_disk_usage_report_image_name }}"
  delegate_to: localhost

# OpenShift cron job to create a qdirstat-compatible report every morning.
- name: BuildConfig for the customized Perl Docker image
  openshift:
    state: latest
    apiVersion: build.openshift.io/v1
    kind: BuildConfig
    metadata:
      name: perl-disk-usage-report
      namespace: "{{ openshift_namespace }}"
    spec:
      output:
        to:
          kind: "DockerImage"
          name: "docker-registry.default.svc:5000/{{ openshift_namespace }}/perl-disk-usage-report:latest"
      source:
        type: Dockerfile
        dockerfile: |
          FROM perl
          RUN cpan URI::Escape
      runPolicy: Serial
      strategy:
        dockerStrategy:
          noCache: true
        type: Docker
      successfulBuildsHistoryLimit: 5

- name: Perl script as a ConfigMap
  openshift:
    state: latest
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: srv-disk-usage-report-scripts
      namespace: "{{ openshift_namespace }}"
    data:
      # A Jinja "include" doesn't work here, because the include
      # directory is random and Jinja forbids leaving it with ../
      # or / (think path traversal attacks). The Ansible "lookup"
      # function comes to the rescue:
      qdirstat-cache-writer: '{{ lookup("file", "templates/qdirstat-cache-writer") }}'

- name: Cron job
  openshift:
    state: latest
    apiVersion: batch/v1beta1
    kind: CronJob
    metadata:
      name: srv-disk-usage-report
      namespace: "{{ openshift_namespace }}"
    spec:
      concurrencyPolicy: Forbid
      schedule: "{{ disk_usage_schedule | default('5 03 * * *') | expand_asap }}"
      jobTemplate:
        spec:
          template:
            spec:
              restartPolicy: Never
              containers:
                - name: qdirstat-cache-writer
                  image: "docker-registry.default.svc:5000/{{ openshift_namespace }}/perl-disk-usage-report:latest"
                  imagePullPolicy: Always
                  command:
                    - /bin/sh
                    - -c
                    - |
                      OUTDIR=/srv/batch/disk-usage-report
                      TARGET=/srv
                      exec >> $OUTDIR/log.txt 2>&1; set -e -x; date; id
                      /scripts/qdirstat-cache-writer $TARGET $OUTDIR/qdirstat.NEW
                      gzip -c $OUTDIR/qdirstat.NEW > $OUTDIR/qdirstat.gz

                      # Kick off disk-usage-metrics container
                      curl http://localhost:8080/

                      rm $OUTDIR/qdirstat.NEW
                  volumeMounts:
                    - name: scripts
                      mountPath: /scripts
                    - name: srv
                      mountPath: /srv
                - name: "{{ monitoring_disk_usage_report_image_name }}"
                  image: "docker-registry.default.svc:5000/{{ openshift_namespace }}/{{ monitoring_disk_usage_report_image_name }}:latest"
                  imagePullPolicy: Always
                  command:
                    - node
                    - -r
                    - ts-node/register
                    - index.ts
                    - -i
                    - /srv/batch/disk-usage-report/qdirstat.NEW
                    - -p
                    - "{{ monitoring_pushgateway_url }}"
                    - --webhook
                  volumeMounts:
                    - name: srv
                      mountPath: /srv
              volumes:
              - name: scripts
                configMap:
                  name: srv-disk-usage-report-scripts
                  items:
                    - key: qdirstat-cache-writer
                      path: qdirstat-cache-writer
                      mode: 0755
              - name: srv
                persistentVolumeClaim:
                  claimName: wordpress-0
