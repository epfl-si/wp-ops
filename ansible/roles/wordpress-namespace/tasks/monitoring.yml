- include_vars: monitoring-secrets.yml
  tags: always

- name: Secret - Bot Token (Telegram)
  kubernetes.core.k8s:
    definition:
      apiVersion: v1
      kind: Secret
      type: Opaque
      metadata:
        name: telegram-bot-token
        namespace: "{{ inventory_namespace }}"
      data:
        access_token: "{{ telegram_bot_token | b64encode }}"

- name: Monitoring - AlertmanagerConfig
  kubernetes.core.k8s:
    definition:
      apiVersion: monitoring.coreos.com/v1beta1
      kind: AlertmanagerConfig
      metadata:
        name: alertmanager-telegram
        namespace: "{{ inventory_namespace }}"
      spec:
        route:
          receiver: "telegram"
          groupBy: ["instance"]
          groupWait: 20s
          groupInterval: 5m
          repeatInterval: 3h
          matchers:
            - name: sendto
              value: telegram
              matchType: "="
        receivers:
          - name: "telegram"
            telegramConfigs:
              - botToken:
                  name: telegram-bot-token
                  key: access_token
                chatID: "{{ telegram_chat_id }}"
                message: |
                  {% raw %}
                  {{ range .Alerts }}
                  {{ if eq .Status "firing" }}
                  ðŸ”¥ FIRING -- {{ .Annotations.summary }}
                  {{ .Annotations.description }}
                  Started at (UTC): {{ .StartsAt.Format "2006-01-02 15:04:05" }}
                  {{ else if eq .Status "resolved" }}
                  âœ… RESOLVED -- {{ .Annotations.summary }}
                  {{ .Annotations.description }}
                  Started at (UTC): {{ .StartsAt.Format "2006-01-02 15:04:05" }}
                  Ended at (UTC): {{ .EndsAt.Format "2006-01-02 15:04:05" }}
                  {{ end }}
                  {{ end }}
                  {% endraw %}
                sendResolved: true

- name: Monitoring - PrometheusRule
  kubernetes.core.k8s:
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: PrometheusRule
      metadata:
        name: wordpress-alerts
        namespace: "{{ inventory_namespace }}"
      spec:
        groups:
          - name: php-fpm-alerts
            rules:
              - alert: PhpFpmHighProcessRequestDuration
                expr: >
                  phpfpm_process_request_duration > 30 * 1000 * 1000
                for: 2m
                labels:
                  severity: critical
                  sendto: telegram
                annotations:
                  summary: "PHP-FPM High process request duration"
                  description: >-
                    {% raw -%}
                    PHP-FPM process request duration exceeded 30s for more than 2 minutes.
                    (pod: {{ $labels.pod }}, instance: {{ $labels.instance }})
                    {%- endraw %}
          - name: nginx-alerts
            rules:
              - alert: NginxClientClosedRequests
                expr: >
                  rate(nginx_http_requests_total{status="499", namespace="{{ inventory_namespace }}"}[2m]) > 0
                for: 2m
                labels:
                  severity: warning
                  sendto: telegram
                annotations:
                  summary: "nginx 499 Errors Detected"
                  description: >-
                    {% raw -%}
                    nginx is returning HTTP 499 errors (Client Closed Request) for more than 2 minutes.
                    (pod: {{ $labels.pod }}, instance: {{ $labels.instance }})
                    {%- endraw %}
              - alert: NginxInternalServerError
                expr: >
                  rate(nginx_http_requests_total{status="500", namespace="{{ inventory_namespace }}"}[2m]) > 0
                for: 2m
                labels:
                  severity: critical
                  sendto: telegram
                annotations:
                  summary: "nginx 500 Errors Detected"
                  description: >-
                    {% raw -%}
                    nginx is returning HTTP 500 errors for more than 2 minutes.
                    (pod: {{ $labels.pod }}, instance: {{ $labels.instance }})
                    {%- endraw %}
              - alert: NginxGatewayTimeout
                expr: >
                  rate(nginx_http_requests_total{status="504", namespace="{{ inventory_namespace }}"}[2m]) > 0
                for: 2m
                labels:
                  severity: critical
                  sendto: telegram
                annotations:
                  summary: "nginx 504 Errors Detected"
                  description: >-
                    {% raw -%}
                    nginx is returning HTTP 504 errors (Gateway Timeout) for more than 2 minutes.
                    (pod: {{ $labels.pod }}, instance: {{ $labels.instance }})
                    {%- endraw %}
          - name: pod-alerts
            rules:
              - alert: WordPressNginxPodCountMismatch
                expr: >
                  kube_deployment_status_replicas_available{deployment="wp-nginx", namespace="{{ inventory_namespace }}"} 
                  != kube_deployment_spec_replicas{deployment="wp-nginx", namespace="{{ inventory_namespace }}"}
                for: 3m
                labels:
                  severity: critical
                  sendto: telegram
                annotations:
                  summary: "Pod count mismatch (wp-nginx)"
                  description: "The deployment wp-nginx has not the desired number of pods for over 3 minutes."
          - name: monitoring-alerts
            rules:
              - alert: NoMonitoring
                expr: >
                  up{namespace="{{ inventory_namespace }}"} == 0
                for: 3m
                labels:
                  severity: critical
                  sendto: telegram
                annotations:
                  summary: "Monitoring target is down"
                  description: >-
                    {% raw -%}
                    The Prometheus target {{ $labels.endpoint }} (job: {{ $labels.job }}, pod: {{ $labels.pod }}, instance: {{ $labels.instance }})
                    has been down for over 3 minutes.
                    {%- endraw %}
